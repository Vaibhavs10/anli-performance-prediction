{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0d7ec495c5f58bd4b22e9225a18398c3dcdacf9e275ce50867fb77cc7ed238bef",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "d7ec495c5f58bd4b22e9225a18398c3dcdacf9e275ce50867fb77cc7ed238bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from collections import defaultdict \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\utils\")\n",
    "    sys.path.append(module_path+\"\\\\models\")\n",
    "\n",
    "import vectorizer\n",
    "from decision_tree import BinaryDecisionTree\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = vectorizer.parse_and_return_rows('../utils/data/processed_data/dev.csv')\n",
    "vocabulary, vocabulary_length = vectorizer.return_len_and_vocabulary(rows)\n",
    "word_to_index = vectorizer.create_token_index(vocabulary)\n",
    "\n",
    "# make training instances with the first hypothesis\n",
    "training_instances  = [(row[1] + \" \" + row[2] + \" \" + row[3], 1 if row[5] == '1' else 0) for row in rows]\n",
    "\n",
    "# add training instances with the second hypothesis\n",
    "training_instances += [(row[1] + \" \" + row[2] + \" \" + row[4], 1 if row[5] == '2' else 0) for row in rows]\n",
    "\n",
    "# change the text into sparse incidence vectors\n",
    "vectorized_training_instances = [(vectorizer.sparse_incidence_vector(text, word_to_index), label) for (text, label) in training_instances]\n",
    "\n",
    "# convert from list of (vector, label) tuples into two separate lists\n",
    "[x, y] = [list(t) for t in zip(*vectorized_training_instances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = vectorizer.parse_and_return_rows('../utils/data/processed_data/dev.csv')\n",
    "\n",
    "# make training instances with the first hypothesis\n",
    "test_instances  = [(row[1] + \" \" + row[2] + \" \" + row[3], 1 if row[5] == '1' else 0) for row in test_rows]\n",
    "\n",
    "# add training instances with the second hypothesis\n",
    "test_instances += [(row[1] + \" \" + row[2] + \" \" + row[4], 1 if row[5] == '2' else 0) for row in test_rows]\n",
    "\n",
    "# change the text into sparse incidence vectors\n",
    "vectorized_test_instances = [(vectorizer.sparse_incidence_vector(text, word_to_index), label) for (text, label) in test_instances]\n",
    "\n",
    "# convert from list of (vector, label) tuples into two separate lists\n",
    "[x_test, y_test] = [list(t) for t in zip(*vectorized_test_instances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_experiment(max_depth, subset_size):\n",
    "    start = time.time()\n",
    "\n",
    "    decision_tree = BinaryDecisionTree()\n",
    "    decision_tree.initialize_training(x, y)\n",
    "\n",
    "    can_keep_expanding = True\n",
    "    while can_keep_expanding:\n",
    "        if max_depth is not None and decision_tree.current_depth >= max_depth:\n",
    "            return\n",
    "        start = time.time()\n",
    "\n",
    "        can_keep_expanding = decision_tree.expand_tree(subset_size)\n",
    "\n",
    "        end = time.time()\n",
    "        \n",
    "        predictions = []\n",
    "        for instance in x_test:\n",
    "            predictions.append(decision_tree.predict_class(instance))\n",
    "\n",
    "        accuracy = evaluation.calculate_accuracy(predictions, y_test)\n",
    "        print(\"Depth: \", decision_tree.current_depth, \"Total nodes: \", decision_tree.total_nodes, \"Current accuracy: \", accuracy, \"Time taken: \", end - start)\n",
    "\n",
    "    return decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = do_experiment(max_depth=100, subset_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = do_experiment(max_depth=100, subset_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aba89c9a2a12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-820073a084bd>\u001b[0m in \u001b[0;36mdo_experiment\u001b[1;34m(max_depth, subset_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdecision_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcan_keep_expanding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Emkin\\Documents\\Uni stuttgart\\SoSe2021\\Team Lab\\nlp-teamlab\\models\\decision_tree.py\u001b[0m in \u001b[0;36minitialize_training\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryDecisionTreeNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf_nodes_to_split_at_current_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaf_nodes_to_split_at_next_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "tree = do_experiment(max_depth=100, subset_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}