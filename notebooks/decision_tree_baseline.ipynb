{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0d7ec495c5f58bd4b22e9225a18398c3dcdacf9e275ce50867fb77cc7ed238bef",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "d7ec495c5f58bd4b22e9225a18398c3dcdacf9e275ce50867fb77cc7ed238bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from collections import defaultdict \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\utils\")\n",
    "    sys.path.append(module_path+\"\\\\models\")\n",
    "\n",
    "import vectorizer\n",
    "from decision_tree import BinaryDecisionTree\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features1(rows, word_to_index):\n",
    "    # make training instances with the first hypothesis\n",
    "    instances  = [(row[1] + \" \" + row[2] + \" \" + row[3], 1 if row[5] == '1' else 0) for row in rows]\n",
    "\n",
    "    # add training instances with the second hypothesis\n",
    "    instances += [(row[1] + \" \" + row[2] + \" \" + row[4], 1 if row[5] == '2' else 0) for row in rows]\n",
    "\n",
    "    # change the text into sparse incidence vectors\n",
    "    vectorized_instances = [(vectorizer.sparse_incidence_vector(text, word_to_index), label) for (text, label) in instances]\n",
    "\n",
    "    # convert from list of (vector, label) tuples into two separate lists\n",
    "    [x, y] = [list(t) for t in zip(*vectorized_instances)]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def features2(rows, word_to_index):\n",
    "    # make training instances with the first hypothesis\n",
    "    instances  = [(row[1] + \" \" + row[2], row[3], 1 if row[5] == '1' else 0) for row in rows]\n",
    "\n",
    "    # add training instances with the second hypothesis\n",
    "    instances += [(row[1] + \" \" + row[2], row[4], 1 if row[5] == '2' else 0) for row in rows]\n",
    "\n",
    "    # change the text into sparse incidence vectors\n",
    "    vectorized_instances = [(vectorizer.sparse_incidence_vector(observations, word_to_index).intersection(vectorizer.sparse_incidence_vector(hypothesis, word_to_index)), label) for (observations, hypothesis, label) in instances]\n",
    "\n",
    "    # convert from list of (vector, label) tuples into two separate lists\n",
    "    [x, y] = [list(t) for t in zip(*vectorized_instances)]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = vectorizer.parse_and_return_rows('../utils/data/processed_data/train.csv')\n",
    "vocabulary, vocabulary_length = vectorizer.return_len_and_vocabulary(rows)\n",
    "word_to_index = vectorizer.create_token_index(vocabulary)\n",
    "x, y = features2(rows, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = vectorizer.parse_and_return_rows('../utils/data/processed_data/dev.csv')\n",
    "\n",
    "x_test, y_test = features2(test_rows, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(max_depth, subset_size, num_threads=1, print_logs=True, decision_tree=None, logs=[], accuracy_frequency=10):\n",
    "    start = time.time()\n",
    "\n",
    "    if decision_tree is None:\n",
    "        decision_tree = BinaryDecisionTree()\n",
    "    decision_tree.initialize_training(x, y)\n",
    "\n",
    "    can_keep_expanding = True\n",
    "\n",
    "    while can_keep_expanding:\n",
    "        if max_depth is not None and decision_tree.current_depth >= max_depth:\n",
    "            return logs, decision_tree\n",
    "        one_layer_start = time.time()\n",
    "\n",
    "        can_keep_expanding = decision_tree.expand_tree(subset_size, num_threads)\n",
    "\n",
    "        one_layer_end = time.time()\n",
    "        \n",
    "        layer_time = one_layer_end - one_layer_start\n",
    "        total_time = one_layer_end - start\n",
    "        if print_logs:\n",
    "            print(\"Depth: \", decision_tree.current_depth, \"Total nodes: \", decision_tree.total_nodes, \"Time taken on layer: \", layer_time, \"Total time taken: \", total_time)\n",
    "        logs.append((decision_tree.current_depth, decision_tree.total_nodes, layer_time, total_time))\n",
    "\n",
    "        if decision_tree.current_depth % accuracy_frequency == 0:\n",
    "            print(\"dev: \", calculate_accuracy(decision_tree, x_test, y_test))\n",
    "            print(\"train: \", calculate_accuracy(decision_tree, x, y))\n",
    "\n",
    "    return logs, decision_tree\n",
    "\n",
    "def calculate_accuracy(decision_tree, x, y):\n",
    "    predictions = []\n",
    "    for instance in x:\n",
    "        predictions.append(decision_tree.predict_class(instance))\n",
    "    return evaluation.calculate_accuracy(predictions, y)\n",
    "\n",
    "def calculate_accuracy_at_all_depths(decision_tree, x, y):\n",
    "    accuracies = []\n",
    "    predictions_at_all_depths = decision_tree.predict_classes_at_all_depths(x)\n",
    "\n",
    "    # calculate transpose of predictions \n",
    "    predictions_at_all_depths = list(map(list, zip(*predictions_at_all_depths)))\n",
    "\n",
    "    for predictions_at_depth in predictions_at_all_depths:\n",
    "        accuracy = evaluation.calculate_accuracy(predictions_at_depth, y)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies\n",
    "\n",
    "def save_results(logs, train_accuracies, dev_accuracies, file_name):\n",
    "    file = open(file_name, \"w\")\n",
    "    file.write(\"acc_train,acc_dev,depth,nodes,time_for_layer,total_time\\n\")\n",
    "    for i, log in enumerate(logs):\n",
    "        message = \"%s,%s,%s,%s,%s,%s\\n\" % (train_accuracies[i], dev_accuracies[i], log[0], log[1], log[2], log[3])\n",
    "        file.write(message)\n",
    "    file.close()\n",
    "\n",
    "def do_experiment(max_depth, subset_size, result_file_name, num_threads=1, print_logs=True, accuracy_frequency=10, tree=None, logs=[]):\n",
    "    logs, tree = train_tree(max_depth, subset_size, num_threads, print_logs, tree, logs, accuracy_frequency)\n",
    "    print(\"Calculating accuracy at all depths...\")\n",
    "    start = time.time()\n",
    "    train_accuracies = calculate_accuracy_at_all_depths(tree, x, y)\n",
    "    dev_accuracies = calculate_accuracy_at_all_depths(tree, x_test, y_test)\n",
    "    end = time.time()\n",
    "    print(\"Time taken: \", end - start)\n",
    "    print(\"Final train accuracy: \", train_accuracies[-1])\n",
    "    print(\"Final dev accuracy: \", dev_accuracies[-1])\n",
    "    save_results(logs, train_accuracies, dev_accuracies, result_file_name)\n",
    "    return logs, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Depth:  1 Total nodes:  1 Time taken on layer:  3.4729671478271484 Total time taken:  3.507969856262207\n",
      "Depth:  2 Total nodes:  3 Time taken on layer:  4.172904968261719 Total time taken:  7.6818718910217285\n",
      "Depth:  3 Total nodes:  7 Time taken on layer:  4.1800689697265625 Total time taken:  11.861940860748291\n",
      "Depth:  4 Total nodes:  13 Time taken on layer:  4.4804301261901855 Total time taken:  16.343372344970703\n",
      "Depth:  5 Total nodes:  21 Time taken on layer:  5.76399827003479 Total time taken:  22.107370615005493\n",
      "Depth:  6 Total nodes:  31 Time taken on layer:  6.451127767562866 Total time taken:  28.559501886367798\n",
      "Depth:  7 Total nodes:  43 Time taken on layer:  5.135952949523926 Total time taken:  33.695454835891724\n",
      "Depth:  8 Total nodes:  61 Time taken on layer:  5.071433067321777 Total time taken:  38.767887115478516\n",
      "Depth:  9 Total nodes:  81 Time taken on layer:  7.344165086746216 Total time taken:  46.11305284500122\n",
      "Depth:  10 Total nodes:  105 Time taken on layer:  7.790454864501953 Total time taken:  53.903507709503174\n",
      "dev:  50.391644908616186\n",
      "train:  50.64778902943638\n",
      "Calculating accuracy at all depths...\n",
      "Time taken:  6.915629863739014\n",
      "Final train accuracy:  50.64778902943638\n",
      "Final dev accuracy:  50.391644908616186\n"
     ]
    }
   ],
   "source": [
    "tree = BinaryDecisionTree()\n",
    "logs = []\n",
    "file_name = \"e15_subset5000.csv\"\n",
    "logs, tree = do_experiment(max_depth=10000, subset_size=5000, num_threads=5, result_file_name=file_name, accuracy_frequency=10, tree=tree, logs=logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating accuracy at all depths...\n",
      "Time taken:  0.8800668716430664\n",
      "Final accuracy:  49.90208877284596\n"
     ]
    }
   ],
   "source": [
    "# use this to save the results of a run that was cancelled early  \n",
    "print(\"Calculating accuracy at all depths...\")\n",
    "start = time.time()\n",
    "train_accuracies = calculate_accuracy_at_all_depths(tree, x, y)\n",
    "dev_accuracies = calculate_accuracy_at_all_depths(tree, x_test, y_test)\n",
    "end = time.time()\n",
    "print(\"Time taken: \", end - start)\n",
    "print(\"Final train accuracy: \", train_accuracies[-1])\n",
    "print(\"Final dev accuracy: \", dev_accuracies[-1])\n",
    "save_results(logs, train_accuracies, dev_accuracies, result_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}